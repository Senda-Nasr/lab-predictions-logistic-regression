{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a40d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b772003",
   "metadata": {},
   "outputs": [],
   "source": [
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50439be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = 'mysql+pymysql://root:' + password + '@localhost/sakila'\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981505d9",
   "metadata": {},
   "outputs": [],
   "source": [
    " query = text(\"\"\"SELECT f.title, f.length, f.rating, f.rental_rate,\n",
    " c.name as category\n",
    " FROM sakila.film as f\n",
    " left join film_category fc\n",
    " on f.film_id = fc.film_id\n",
    " left join category c\n",
    " on fc.category_id = c.category_id\n",
    "\"\"\")\n",
    "    \n",
    "important_features= pd.read_sql_query(query, engine)\n",
    "display(important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773fb71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query= \"\"\"\n",
    "SELECT f.title, MAX(CASE WHEN MONTH(r.rental_date) = 5 THEN 'True' ELSE 'False' END) as rented_in_may\n",
    "FROM film as f\n",
    "LEFT JOIN inventory as i ON f.film_id = i.film_id\n",
    "LEFT JOIN rental as r ON i.inventory_id = r.inventory_id\n",
    "GROUP BY f.title;\n",
    "\"\"\"\n",
    "\n",
    "rentals_may= pd.read_sql_query(query, engine)\n",
    "rentals_may['rented_in_may'] = rentals_may['rented_in_may'].apply(lambda x: x.lower() == 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f7f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "films = pd.merge(important_features, rentals_may, on='title')\n",
    "display(films)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e75a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "films.isna().sum() #checking to make sure that there are no nulls in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06d2216",
   "metadata": {},
   "outputs": [],
   "source": [
    "films.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6663bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "films['rating'].value_counts()\n",
    "films['rental_rate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50822d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will first convert the rental_rate column to ordinal categorical\n",
    "rep = {0.99: 'Low', 2.99: 'Medium', 4.99: 'High'}\n",
    "films['rental_rate'] = films['rental_rate'].replace(rep)\n",
    "films['rental_rate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e345949",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(films.info()) #lengths is the only numerical object\n",
    "display(films.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada6ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing X-y split\n",
    "y = films['rented_in_may']\n",
    "X = films.drop(['rented_in_may', 'title'], axis=1)\n",
    "\n",
    "# Peforming train-test-split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=181)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee61210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the one hot encoder on the categorical variables\n",
    "X_train_categorical = X_train.select_dtypes('object')\n",
    "X_test_categorical  = X_test.select_dtypes('object')\n",
    "\n",
    "display(X_train_categorical.head())\n",
    "\n",
    "#importing onehotencoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#fitting the onehotencoder on training set\n",
    "encoder = OneHotEncoder(drop='first')\n",
    "encoder.fit(X_train_categorical)\n",
    "\n",
    "#applying the encoder to train and test sets\n",
    "X_train_cat_np = encoder.transform(X_train_categorical).toarray()\n",
    "X_test_cat_np  = encoder.transform(X_test_categorical).toarray()\n",
    "\n",
    "#displaying the encoded train and test sets\n",
    "display(X_train_cat_np)\n",
    "X_train_cat = pd.DataFrame(X_train_cat_np, columns=encoder.get_feature_names_out(), \n",
    "                           index=X_train_categorical.index)\n",
    "X_test_cat  = pd.DataFrame(X_test_cat_np,  columns=encoder.get_feature_names_out(),\n",
    "                          index=X_test_categorical.index)\n",
    "display(X_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2fc6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train_num = X_train.select_dtypes(include = np.number) \n",
    "X_test_num  = X_test.select_dtypes(include = np.number)\n",
    "\n",
    "# Scaling data\n",
    "transformer = MinMaxScaler().fit(X_train_num) \n",
    "\n",
    "X_train_normalized = transformer.transform(X_train_num)\n",
    "X_test_normalized  = transformer.transform(X_test_num)\n",
    "\n",
    "X_train_norm = pd.DataFrame(X_train_normalized, columns=X_train_num.columns, index= X_train_num.index)\n",
    "X_test_norm  = pd.DataFrame(X_test_normalized, columns=X_test_num.columns, index= X_test_num.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de654ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = pd.concat([X_train_norm, X_train_cat], axis=1)\n",
    "display(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184b1e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classification = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                  multi_class='multinomial')\n",
    "\n",
    "classification.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d623b17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = pd.concat([X_test_norm, X_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a372d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can make predictions on the test set:\n",
    "y_test_pred = classification.predict(X_test_transformed)\n",
    "print(y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7182dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bb7d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification.score(X_test_transformed, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6578ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
